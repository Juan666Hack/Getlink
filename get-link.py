import requests
from os import system as pip
from time import sleep

try:
    from user_agent import generate_user_agent
except:
    pip('pip install user_agent')
    from user_agent import generate_user_agent
try:
    from bs4 import BeautifulSoup
except:
    pip('pip install beautifulsoup4')
    pip('pip install html5lib')
    from bs4 import BeautifulSoup

preboyx = ("""
#---------------------------------------------------------------
â•”â•â•—â•”â•â•—â•”â•¦â•—  
â•‘ â•¦â•‘â•£  â•‘   
â•šâ•â•â•šâ•â• â•©   
â•¦  â•¦â•”â•—â•”â•¦â•”â• 
â•‘  â•‘â•‘â•‘â•‘â• â•©â•— 
â•©â•â•â•©â•â•šâ•â•© â•© 

#---------------------------------------------------------------
.          JUANHACK DOMINA POR SIEMPRE.
#---------------------------------------------------------------
""")
print('\033[1;32;40m' + preboyx)  # Imprime en verde
url = input('\033[1;32;40m[~] Ingresa el enlace del sitio: ')  # Imprime en verde

r = requests.get(url, headers={'user_agent': generate_user_agent()})
if r.status_code == 200:
    print('\033[1;32;40m[â€¢] Extrayendo enlaces ..\n')  # Imprime en verde
    x = BeautifulSoup(r.text, 'html.parser')
    cc = list(x.find_all('a'))
    for i in cc:
        try:
            line = str(i['href']).replace(' ', '').replace('#', '')
            if line == '' or line == ' ' or line == '#' or line == '/':
                pass
            else:
                print('\033[1;32;40m[ğŸœ¸] ' + line)  # Imprime en verde
                file = open('links.txt', 'a').write(f'{line}\n')
        except:
            pass
else:
    print('\033[1;31;40m[!] Url del sitio web incorrecto, intÃ©ntalo de nuevo')  # Imprime en rojo
    sleep(3)
    quit()
